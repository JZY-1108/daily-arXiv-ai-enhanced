<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 该论文研究了LLM在程序性序列推理中的能力，通过使用食谱数据集评估模型从打乱步骤中重建正确顺序的表现，发现模型性能随序列长度增加和步骤位移加剧而下降。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在程序性序列推理中的能力，因为步骤顺序直接影响结果，这在如食谱等需要正确排序的领域中至关重要。

Method: 使用食谱数据集，在零样本和少样本设置下评估多个LLM，采用Kendall's Tau、NLCS和NED等排序和序列对齐指标构建综合评价框架。

Result: 模型性能随序列长度增加而下降，输入步骤位移越大（打乱程度越严重），性能退化越明显。

Conclusion: 当前LLM在程序性推理方面存在局限性，特别是在处理更长和更无序的输入时表现不佳。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS是一个基于项目反应理论的自适应测试框架，通过Fisher信息指导的项目选择来评估大语言模型能力，能在保持测量精度的同时减少90%的测试项目。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型评估需要数千个基准项目，成本高且效率低，且所有项目被平等对待，忽略了项目质量和信息量的差异。

Method: 使用项目反应理论(IRT)和Fisher信息指导的项目选择，动态选择最具信息量的测试项目来估计模型能力。

Result: 在HellaSwag基准测试中，仅用42个项目就达到了全基准测试的估计精度(5,608个项目)，平均绝对误差为0.154。项目暴露率低于10%，测试重叠率为16-27%。

Conclusion: ATLAS框架显著提高了评估效率，发现传统静态基准测试存在项目质量问题，IRT评分与传统准确率排名存在显著差异。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: SARC是一个基于情感增强角色聚类的假新闻检测框架，通过识别用户角色来提升检测性能，在多个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法将情感特征作为辅助信号，忽略了相同情感极性可能来自不同角色的用户，限制了捕捉细微模式的能力。

Method: 提出SARC框架：1）通过BiGRU和注意力机制生成用户特征；2）构建可微分深度聚类模块自动分类用户角色；3）联合优化角色聚类和假新闻检测目标。

Result: 在RumourEval-19和Weibo-comp两个基准数据集上的实验结果表明，SARC在所有指标上都优于基线模型。

Conclusion: SARC通过情感增强的角色聚类有效提升了假新闻检测性能，证明了考虑用户角色差异的重要性。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 该论文提出将指令层级解析重构为推理任务，通过构建VerIH数据集和轻量级强化学习训练，使LLM能够优先处理系统指令而非用户指令，从而提升模型的可控性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实决策中承担重要角色，需要解决来自多个来源（如开发者、用户、工具）的竞争性指令，建立指令层级对于LLM的可靠性和可控性至关重要。

Method: 构建VerIH指令层级数据集，包含对齐和冲突的系统-用户指令，采用轻量级强化学习训练模型，使其能够推理指令间的关系并优先处理高级别指令。

Result: 微调后的模型在指令遵循和指令层级基准测试中表现一致提升，推理能力可泛化到安全关键场景，增强了对越狱和提示注入攻击的鲁棒性。

Conclusion: 通过指令层级推理为构建可靠LLM提供了实用路径，系统提示的更新能够产生可控且鲁棒的模型行为变化。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [5] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe是一个用于开发和评估检索增强生成(RAG)系统的Python框架，包含五个模块化组件，支持科学可复现性和本地部署。评估显示RAG性能仍不及Oracle Context，而Hybrid BM25在所有数据集上表现最佳，重排序仅带来边际性能提升但增加延迟。


<details>
  <summary>Details</summary>
Motivation: 为简化基于大语言模型和嵌入模型的RAG系统开发与评估，提供一个模块化、可扩展的框架，强调科学可复现性和多样化评估指标。

Method: 开发包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个组件的模块化框架，支持灵活实验和可扩展开发。在包含25k问答对和51k文档的多个基准数据集上进行广泛评估。

Result: RAG性能仍低于Oracle Context；Hybrid BM25在所有四个数据集上表现最佳；重排序仅带来边际性能提升但显著增加响应延迟。

Conclusion: EncouRAGe框架有效支持RAG系统的开发与评估，但当前RAG方法仍有改进空间，Hybrid BM25是更可靠的选择，重排序的实际价值有限。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [6] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 多MentalRoBERTa是一个基于RoBERTa微调的心理健康多分类模型，用于从社交媒体文本中检测压力、焦虑、抑郁、PTSD、自杀意念和中性话语，在性能上优于传统方法和领域特定模型。


<details>
  <summary>Details</summary>
Motivation: 早期检测心理健康障碍对于及时支持、风险评估和转诊至关重要，特别是在社交媒体文本中识别常见心理健康状况。

Method: 使用多个精选数据集进行数据探索，分析类别重叠，采用微调的RoBERTa模型进行多分类，并与传统机器学习、领域特定transformer和基于提示的大语言模型进行比较。

Result: multiMentalRoBERTa在六分类设置中达到0.839的宏F1分数，在五分类设置（排除压力）中达到0.870，优于微调的MentalBERT和基线分类器。

Conclusion: 微调的transformer在敏感情境下提供了可靠且可解释的检测方案，强调了公平性、偏见缓解和人机协同安全协议的重要性，multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [7] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大规模合成语料库，包含250多万个样本，旨在解决阿拉伯语OCR和文档理解资源稀缺问题。该数据集通过真实扫描背景、双语布局和音标感知字体来捕捉阿拉伯文档的复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语在光学字符识别和文档理解领域资源稀缺的问题，为多语言文档分析提供可扩展的视觉真实资源。

Method: 利用真实扫描背景、双语布局和音标感知字体构建合成数据管道，包含文本、表格和图表等多种渲染样式，共生成超过250万个样本。

Result: 在Qwen-2.5-VL模型上微调后，在多个阿拉伯语基准测试中，词错误率和字符错误率持续改善，表格编辑距离相似度和图表提取分数在其他模态上也得到提升。

Conclusion: SynthDocs为多语言文档分析研究提供了一个可扩展且视觉真实的资源，有效提升了阿拉伯语OCR和文档理解的性能。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [8] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG是一个新颖的检索增强生成框架，通过两阶段处理来过滤噪声文档并保留有价值内容，提高RAG系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法通过增加检索文档数量来提高相关性，但这会引入大量噪声文档，反而降低生成响应的准确性。需要一种能有效过滤噪声同时保留有用信息的方法。

Method: 两阶段框架：第一阶段进行查询感知聚类，将相似文档分组并由LLM代理生成答案；第二阶段进行筛选，由评判LLM评估多个代理输出并迭代分离有用和噪声文档，使用策略性合并技术保留有用文档。

Result: 在多个现实数据集上的广泛实验表明，WinnowRAG在效果上优于最先进的基线方法。

Conclusion: WinnowRAG是一个模型无关且无需微调的框架，能有效处理大量文档中的噪声问题，在各种任务中具有良好适应性。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [9] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本文通过系统评估445个LLM基准测试，发现现有评估方法在测量抽象概念（如安全性和鲁棒性）时存在构造效度问题，并提出了8项改进建议。


<details>
  <summary>Details</summary>
Motivation: 可靠评估大型语言模型的能力、安全性和鲁棒性对于部署前识别问题至关重要，但现有基准测试在测量抽象复杂现象时缺乏足够的构造效度。

Method: 组织29名专家评审团队，对自然语言处理和机器学习顶级会议中的445个LLM基准测试进行系统性审查，分析测量现象、任务和评分指标的模式。

Result: 发现现有基准测试在测量现象、任务和评分指标方面存在模式问题，这些模式削弱了最终结论的有效性。

Conclusion: 为研究人员和实践者提供了8项关键建议和详细可操作的指导，以改进LLM基准测试的开发。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [10] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: POLIS-Bench是首个针对政府双语政策场景的LLM评估套件，包含更新的双语语料库、场景化任务设计和双指标评估框架，评估显示推理模型表现最佳，并成功训练出轻量级开源模型达到或超越商业模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分评估LLM在政府政策场景中的表现，需要专门针对双语政策理解和合规性判断的评估体系。

Method: 构建更新的双语政策语料库，设计三个场景化任务（条款检索与解释、解决方案生成、合规性判断），建立语义相似度和准确率的双指标评估框架。

Result: 评估10多个SOTA LLM发现推理模型在跨任务稳定性和准确性方面表现最优，合规性任务最具挑战性；成功训练出轻量级POLIS系列模型，在多个政策子任务上达到或超越商业模型性能。

Conclusion: POLIS-Bench为政府政策场景的LLM评估提供了系统性框架，轻量级开源模型的发展为实际政府部署提供了成本效益高的合规路径。

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [11] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一个基于Gemma 2B架构的轻量级文本到SQL模型，通过资源高效的迭代微调和多提示策略，在SPIDER基准测试中表现出色，超越了多个最先进基线模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级、高效的文本到SQL系统，让用户无需专业编程知识就能与结构化数据库交互，并能在低成本硬件上部署。

Method: 基于开源Gemma 2B架构，采用资源高效的迭代微调方法，结合少样本学习等多种提示策略来提升SQL查询生成准确性。

Result: GEMMA-SQL Instruct变体在SPIDER基准测试中达到66.8%的测试套件准确率和63.3%的精确集匹配准确率，超越了IRNet、RYANSQL和CodeXDavinci等基线模型。

Conclusion: 有效的提示设计和针对性指令调优可以显著提升性能，同时保持高可扩展性和适应性，使GEMMA-SQL成为稳健且易用的文本到SQL系统的实用开源替代方案。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [12] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文挑战了先前关于LLM影响函数计算的认知，证明中间注意力层比嵌入层更适合用于训练样本影响估计，并提出新的评估指标NDR。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型训练样本影响估计方法因计算限制通常只使用部分层，先前研究认为嵌入层最有效，但本文发现这种基于抵消效应的假设不可靠。

Method: 提出理论和实证证据证明抵消效应不可靠，发现中间注意力层更适合影响估计，并提出排名和投票等替代标准平均的聚合方法。

Result: 通过在不同类型和规模的LLM上进行广泛实验，证明第一层不一定比最后一层更适合影响估计，与先前认知相反。

Conclusion: 中间注意力层是更好的影响估计器，NDR指标比抵消效应具有更强的预测能力，为LLM影响估计提供了新的方向。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [13] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR是一个基于检索增强诊断推理代理的系统，用于脑MRI中罕见疾病检测。它通过检索外部医学知识来指导诊断决策，无需额外训练即可提升罕见病理识别能力。


<details>
  <summary>Details</summary>
Motivation: 罕见疾病在医学影像中数据稀缺，导致AI模型表现不佳。受放射科医生查阅病例报告和文献的启发，开发了检索增强系统来应对这一挑战。

Method: 使用AI代理访问外部医学知识，通过句子转换器嵌入病例报告和文献，并用FAISS索引实现高效相似性搜索，检索临床相关证据指导诊断。

Result: 在包含280种罕见疾病的NOVA数据集上，RADAR实现了最高10.2%的性能提升，特别是对开源模型如DeepSeek效果最显著。

Conclusion: 检索增强推理是医学影像中低流行率条件的强大范式，不仅能提高准确性，还能提供基于文献的可解释性解释。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [14] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 提出基于信息熵方差的图像描述多样性度量方法，比较人类与模型在语言多样性上的差异，发现评估结果高度依赖于使用的评分模型。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述模型在语言多样性评估方面缺乏可靠指标，需要开发能够准确衡量描述多样性的方法。

Method: 使用信息熵方差作为多样性度量，在MSCOCO数据集上比较5种先进视觉语言模型与人类描述，分别用图像描述训练的n-gram模型和通用语言模型进行评分。

Result: 使用图像描述训练的模型时，人类描述的信息熵方差约为模型的两倍；但使用通用语言模型评分时，结果完全相反。

Conclusion: 图像描述多样性评估结果高度依赖于评分模型，稳健的多样性评估需要使用多个评分模型来报告信息熵值。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [15] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: 提出ERPO框架解决RLVR训练中残差提示问题，通过自适应温度调整鼓励探索，在数学推理基准上超越基线方法


<details>
  <summary>Details</summary>
Motivation: 随着RLVR训练时间延长和模型规模扩大，更多训练提示变为残差提示（零方差奖励），导致训练信号减少、多样性降低，影响训练效果

Method: ERPO框架维护每个提示的历史跟踪器，自适应增加残差提示的采样温度，鼓励生成更多样化的推理轨迹，重新激活训练信号

Result: 在Qwen2.5系列上的实证结果显示，ERPO在多个数学推理基准上持续超越强基线方法

Conclusion: ERPO通过有效利用残差提示，解决了RLVR训练中的信号衰减问题，提升了模型推理能力

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [16] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究发现基础LLMs在语义校准方面表现良好，能够有意义地评估开放域问答任务的置信度，尽管没有经过专门训练。理论解释了语义校准作为下一个词预测副产品的机制，并验证了RL指令微调和思维链会破坏这种校准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常缺乏对其输出的有意义的置信度估计。虽然基础LLMs显示出下一个词校准，但不清楚它们能否在词级别之外评估响应的实际含义的置信度。

Method: 使用基于采样的语义校准概念，建立B-校准理论框架，通过连接校准和局部损失最优性来解释语义校准机制。通过实验验证理论预测。

Result: 基础LLMs在问答任务中表现出语义校准，RL指令微调会系统性地破坏这种校准，思维链推理也会破坏校准。

Conclusion: 该研究首次提供了关于LLMs中语义校准何时以及为何出现的原理性解释，表明基础LLMs能够进行有意义的语义置信度评估，但后续优化过程可能破坏这种能力。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [17] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: LLMs可以通过单一rank-1 LoRA适配器可靠地诱导行为自我意识，该能力表现为激活空间中的单一转向向量，且具有任务特定的局部化特征。


<details>
  <summary>Details</summary>
Motivation: LLMs展现出的行为自我意识能力引发安全担忧，可能使模型在评估时更好地隐藏真实能力，因此需要研究其产生的最小条件和机制过程。

Method: 通过在指令调优的LLMs上使用低秩适配器(LoRA)进行受控微调实验，特别是使用单一rank-1 LoRA适配器。

Result: 发现自我意识可以通过单一rank-1 LoRA可靠诱导；学习到的自我意识行为可被激活空间中的单一转向向量捕获；自我意识是非普遍且领域局部化的，在不同任务间有独立表示。

Conclusion: 行为自我意识表现为领域特定的线性特征，易于诱导和调节。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [18] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: SDS KoPub VDR是首个大规模公开的韩文公文检索基准，包含361份真实文档和600个查询-页面-答案三元组，支持文本检索和多模态检索任务评估。


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索基准主要关注英文文档，忽视了非英语语言和官方出版物的结构复杂性，需要填补韩文公文检索领域的空白。

Method: 基于361份真实韩文公文构建语料库，使用多模态模型生成查询并经过人工验证，建立包含文本检索和多模态检索的双任务评估框架。

Result: 评估显示在多模态场景下存在显著的性能差距，特别是在需要跨模态推理的任务中，即使是先进模型也表现不佳。

Conclusion: SDS KoPub VDR为复杂真实世界文档智能提供了基础资源，能够进行严格的文本和多模态检索评估，并为多模态AI发展指明方向。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [19] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种内存增强架构，通过选择性记忆策略和特征显著性评分来学习存储重要信息，在严格预算约束下实现长文档处理，相比基线RAG节省72.4%内存且性能仅下降1.0%。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理长上下文时面临显著的计算和内存限制，尽管应用需求增长，但现有方法成本过高，不适合资源受限的部署环境。

Method: 结合选择性记忆策略与基于特征的显著性评分（实体密度、TF-IDF、语篇标记、位置偏差），使用学习门控机制和BM25稀疏检索进行高效信息访问。

Result: 在700个问答对上的实验显示，BudgetMem在长文档上仅产生1.0% F1分数下降，同时节省72.4%内存；预算敏感性分析表明其优势随文档长度增加而增强。

Conclusion: BudgetMem为在有限硬件上部署能力强的长上下文系统提供了实用途径，民主化了对高级语言理解能力的访问。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [20] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一个基于集体感知的基准线和数据集推荐框架，通过自动化数据收集管道和增强的检索重排方法，显著提升了AI实验中数据集和基准线推荐的准确性和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在数据覆盖范围有限、过度依赖内容相似性而忽视实验适用性的问题，需要开发更全面可靠的自动化实验设计工具。

Method: 1) 自动化数据收集管道链接论文与使用的基准线和数据集；2) 集体感知增强检索器结合自描述和引用上下文；3) 推理增强重排器构建显式推理链并生成可解释的推荐理由。

Result: 构建的数据集覆盖了过去五年顶级AI会议中85%的数据集和基准线，在Recall@20和HitRate@5指标上分别比最强基线提升了5.85%和8.30%。

Conclusion: 该方法推进了实验设计的可靠、可解释自动化，为科学探索提供了更有效的工具支持。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [21] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本研究提出了一种新的验证方法来检测Wikidata知识图谱中的分类错误、过度泛化的子类链接和冗余连接，并开发了允许用户检查任意实体分类关系的系统。


<details>
  <summary>Details</summary>
Motivation: Wikidata作为最大的开放知识图谱，其宽松的编辑政策导致了分类不一致问题，需要系统性的验证和纠正方法。

Method: 提出并应用新的验证方法来确认分类错误、过度泛化的子类链接和冗余连接，引入新的评估标准判断是否需要修正。

Result: 成功检测到特定领域中存在的分类不一致问题，开发了用户可检查实体分类关系的系统。

Conclusion: 利用Wikidata的众包特性，开发了有效检测和纠正分类不一致问题的系统，提升了知识图谱的质量。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [22] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: LoPT是一种无损并行分词框架，通过字符位置匹配和动态块长度调整，解决了长文本分词中的边界伪影问题，确保与顺序分词结果完全一致，同时显著提升处理速度。


<details>
  <summary>Details</summary>
Motivation: 长文本推理场景对大型语言模型越来越重要，但带来了显著的计算延迟。现有并行分词方法通过文本分割和多进程分词加速处理，但由于合并后的边界伪影导致结果不一致。

Method: 提出LoPT框架，采用基于字符位置的匹配和动态块长度调整，准确对齐和合并分词片段，确保无损分词。

Result: 在多样化长文本数据集上的广泛实验表明，LoPT实现了显著加速，同时保证无损分词。

Conclusion: LoPT提供了理论一致性证明和全面分析研究，验证了方法的鲁棒性，解决了并行分词中的边界对齐问题。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [23] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: LLMs在扮演反派角色时存在系统性困难，安全对齐与角色扮演真实性之间存在冲突


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在模拟非亲社会、反派角色时的能力限制，特别是安全对齐如何影响角色扮演的真实性

Method: 引入Moral RolePlay基准数据集，包含四级道德对齐量表，让LLMs扮演从道德典范到纯粹恶棍的角色，进行大规模评估

Result: 随着角色道德水平下降，角色扮演保真度单调递减；模型在"欺骗性"和"操纵性"等与安全原则直接冲突的特质上表现最差；安全对齐程度高的模型在反派角色扮演上表现特别差

Conclusion: 发现了模型安全性与创意保真度之间的关键张力，为开发更细致、上下文感知的对齐方法奠定了基础

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [24] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本文提出了一种获取中文常见情感事件的方法，通过收集情感事件指示词，使用中文大语言模型生成情感事件，并训练过滤器确保质量，最终构建了包含102,218个高质量情感事件的知识库。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对提高应用效果很重要，但难以获取，特别是与上下文无关的常见或通用情感事件。

Method: 收集中文情感事件指示词，用中文大语言模型生成情感事件，训练过滤器剔除无效结果，使用不同技术分类正面和负面事件。

Result: 获得了102,218个带有情感极性标签的高质量常见情感事件，这是目前唯一的大规模中文情感事件常识知识库。内在评估显示方法有效，外在用例在情感原因提取领域展示了潜力。

Conclusion: 提出的方法能有效获取中文常见情感事件，构建的知识库对情感相关应用有重要价值，相关资源将在论文发表后发布。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [25] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 提出了PBSUITE评估套件，用于系统评估LLM在多轮对抗性对话中遵守多样化行为规范的能力，发现现有模型在单轮场景表现良好，但在多轮对抗交互中合规性显著下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的LLM应用需要在组织特定的政策、法规和品牌准则下运行，而现有通用安全原则无法满足这种多样化需求，需要评估LLM的多元化对齐能力。

Method: 开发了PBSUITE评估套件，包含基于30个行业的300个现实行为政策数据集，以及用于在对抗条件下压力测试模型合规性的动态评估框架。

Result: 领先的开源和闭源LLM在单轮设置中表现出强大的行为政策遵守能力（失败率低于4%），但在多轮对抗交互中合规性显著减弱（失败率高达84%）。

Conclusion: 现有的模型对齐和安全调节方法在真实世界LLM交互中无法连贯地执行多元化行为政策，需要开发更鲁棒和情境感知的多元化对齐技术。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [26] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: UA-Code-Bench是一个针对乌克兰语的代码生成和编程问题解决能力评估基准，包含500个难度分级的问题，评估显示即使是顶级模型也只能解决一半问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注从英语翻译的广泛任务或仅评估简单语言理解，缺乏对低资源语言中代码生成能力的全面评估。

Method: 使用Eolymp平台的500个问题，通过13个领先模型生成Python解决方案，在专用环境中进行隐藏测试以确保代码正确性。

Result: 即使是OpenAI o3和GPT-5等顶级模型也只能解决50%的问题，表明低资源自然语言中的代码生成具有挑战性。

Conclusion: 竞争性编程基准在评估大语言模型方面具有价值，特别是在代表性不足的语言中，为多语言代码生成和推理增强模型的未来研究铺平了道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: IndicVisionBench是首个专注于印度次大陆的大规模多模态基准测试，涵盖英语和10种印度语言，包含OCR、MMT和VQA三个任务，共约5K图像和37K+问答对，评估了8个模型在文化多样性环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大多数视觉语言模型评估基准都是西方中心的，缺乏对文化多样性和多语言环境的测试，需要建立针对印度次大陆的评估框架。

Method: 构建包含13个文化主题的基准测试，涵盖3种多模态任务（OCR、MMT、VQA），收集约5K图像和37K+问答对，并发布10种印度语言的平行语料库。

Result: 评估了8个模型（包括闭源和开源模型），发现当前VLMs在文化多样性环境中存在显著的性能差距。

Conclusion: IndicVisionBench为更包容的多模态研究建立了可复现的评估框架，揭示了当前模型在文化多样性环境中的局限性。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [28] [Knowledge-based anomaly detection for identifying network-induced shape artifacts](https://arxiv.org/abs/2511.04729)
*Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki*

Main category: cs.CV

TL;DR: 提出了一种基于知识的异常检测方法，用于检测合成医学图像中的网络诱导形状伪影，通过两阶段框架（特征提取器和隔离森林检测器）在合成乳腺X光图像数据集上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据虽然能解决训练数据稀缺问题，但未经质量评估可能引入伪影和失真特征，影响模型性能和临床实用性，需要检测网络生成的形状伪影。

Method: 采用两阶段框架：1）新型特征提取器，通过分析解剖边界角度梯度的每图像分布构建专门特征空间；2）基于隔离森林的异常检测器。

Result: 在两个合成乳腺X光数据集上，AUC分别达到0.97和0.91；读者研究显示最异常分区的人机一致性达66%和68%，Kendall-Tau相关性为0.45和0.43。

Conclusion: 该方法推动了合成数据的负责任使用，使开发者能够根据已知解剖约束评估合成图像质量，定位并解决特定问题以提高合成数据集整体质量。

Abstract: Synthetic data provides a promising approach to address data scarcity for
training machine learning models; however, adoption without proper quality
assessments may introduce artifacts, distortions, and unrealistic features that
compromise model performance and clinical utility. This work introduces a novel
knowledge-based anomaly detection method for detecting network-induced shape
artifacts in synthetic images. The introduced method utilizes a two-stage
framework comprising (i) a novel feature extractor that constructs a
specialized feature space by analyzing the per-image distribution of angle
gradients along anatomical boundaries, and (ii) an isolation forest-based
anomaly detector. We demonstrate the effectiveness of the method for
identifying network-induced shape artifacts in two synthetic mammography
datasets from models trained on CSAW-M and VinDr-Mammo patient datasets
respectively. Quantitative evaluation shows that the method successfully
concentrates artifacts in the most anomalous partition (1st percentile), with
AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study
involving three imaging scientists confirmed that images identified by the
method as containing network-induced shape artifacts were also flagged by human
readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the
most anomalous partition, approximately 1.5-2 times higher than the least
anomalous partition. Kendall-Tau correlations between algorithmic and human
rankings were 0.45 and 0.43 for the two datasets, indicating reasonable
agreement despite the challenging nature of subtle artifact detection. This
method is a step forward in the responsible use of synthetic data, as it allows
developers to evaluate synthetic images for known anatomic constraints and
pinpoint and address specific issues to improve the overall quality of a
synthetic dataset.

</details>


### [29] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出条件偏好优化(CPO)方法，通过直接优化控制条件而非生成图像来提升文本到图像生成的可控性，解决了传统方法在高噪声时间步优化困难和DPO方法中图像质量混淆因素的问题。


<details>
  <summary>Details</summary>
Motivation: ControlNet++仅优化低噪声时间步且使用单步近似，忽略了高噪声时间步的贡献并引入近似误差；DPO方法难以确保图像对仅在可控性上存在差异而保持其他因素不变。

Method: 构建获胜和失败的控制信号c^w和c^l，训练模型偏好c^w，通过条件偏好优化消除混淆因素并获得低方差训练目标。

Result: 相比最先进的ControlNet++，CPO在分割任务上降低超过10%的错误率，人体姿态任务降低70-80%，边缘和深度图一致降低2-5%。

Conclusion: CPO在理论上比DPO具有更低的对比损失方差，实验上显著提升了多种控制类型的可控性，且需要更少的计算和存储资源。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [30] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

TL;DR: DARN是一种新颖的解码器架构，通过动态自适应正则化解决卫星图像异质性挑战，在完整微调和高效适应两种模式下都实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 标准适应方法使用固定正则化策略的解码器，无法处理卫星图像的显著异质性，限制了基础模型在地理空间分析中的有效应用。

Method: DARN包含三个关键创新：轻量级任务复杂度预测器、基于预测复杂度动态调整dropout率的自适应dropout调制、以及调节通道激活的动态容量门控。

Result: 在完整微调模式下，DARN在GeoBench基准上达到86.66% mIoU的新SOTA；在高效适应模式下，在Sen1Floods11上达到90.5% mIoU，并在OOD泛化、鲁棒性和少数类性能方面显著提升。

Conclusion: DARN为关键地理空间应用中利用基础模型提供了更智能、鲁棒和高效的方法。

Abstract: Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [31] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 提出基于预训练-微调框架的机器学习方法，从全球多卫星2D图像生成3D云图，首次实现全球瞬时3D云图构建，能准确重建强风暴的3D结构。


<details>
  <summary>Details</summary>
Motivation: 热带气旋预报面临卫星观测有限和云属性解析困难的挑战，现有方法在TC常见区域表现不佳且对强风暴验证不足。

Method: 采用预训练-微调流程，利用全球覆盖的多卫星数据，将2D卫星图像转换为相关云属性的3D云图，并在定制TC数据集上评估。

Result: 首次创建全球瞬时3D云图，准确重建强风暴的3D结构，扩展可用卫星观测并在观测缺失时提供估计。

Conclusion: 该方法对推进TC强化理解和改进预报至关重要，为缺失观测提供估计能力。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [32] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

TL;DR: 提出EETnet，一种专为基于事件的眼动追踪设计的CNN网络，能够在资源受限的微控制器上运行，并提供分类和回归两种架构版本。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的眼动追踪方案大多依赖强大的GPU，无法在嵌入式设备上部署，需要开发能在资源受限设备上运行的解决方案。

Method: 设计卷积神经网络EETnet，使用纯事件数据，提出训练、评估和量化方法，提供分类模型（在网格上检测瞳孔）和回归模型（像素级操作）两种架构。

Result: 开发出能够在微控制器上运行的基于事件的眼动追踪神经网络，并建立了完整的训练和量化流程。

Conclusion: EETnet证明了基于事件的眼动追踪可以在资源受限的嵌入式设备上实现，为低功耗眼动追踪应用提供了可行方案。

Abstract: Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [33] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 3D Gaussian Point Encoder是一种基于学习3D高斯混合的显式逐点嵌入方法，相比传统的PointNet等隐式表示，在3D识别任务中具有更高的计算效率和参数效率。


<details>
  <summary>Details</summary>
Motivation: 3D识别任务中广泛使用隐式表示（如PointNet），但显式几何表示在3D重建领域已显示出优势。本文旨在开发基于3D高斯的显式表示，以提升计算效率和参数效率。

Method: 开发基于自然梯度和从PointNet蒸馏的优化技术，学习能够重建PointNet激活的高斯基。扩展3D高斯泼溅的滤波技术来加速编码器。

Result: 3D高斯点编码器比可比精度的PointNet快2.7倍，内存减少46%，FLOPs减少88%。在Mamba3D中运行快1.27倍，内存和FLOPs分别减少42%和54%。

Conclusion: 3D高斯点编码器提供了一种轻量级的显式表示方法，在CPU设备上也能实现高帧率，为3D识别任务提供了更高效的解决方案。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [34] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 本研究系统分析了Cellpose等通用生物医学图像分割模型的数据冗余和跨域遗忘问题，提出了数据集量化策略来构建紧凑训练子集，并通过选择性重放和域排序策略缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 当前通用生物医学图像分割模型面临两个关键挑战：训练数据冗余程度不明确，以及跨域迁移对模型保留能力的影响未被充分探索。

Method: 1. 提出数据集量化策略构建紧凑多样的训练子集；2. 使用MAE嵌入和t-SNE进行潜在空间分析；3. 进行跨域微调实验评估灾难性遗忘；4. 采用选择性重放和域排序策略。

Result: 1. 仅使用10%数据即可达到性能饱和，显示显著数据冗余；2. 跨域微调导致源域性能显著下降；3. 选择性重放5-10%源数据可有效恢复源性能；4. 训练域排序可改善泛化并减少遗忘。

Conclusion: 生物医学图像分割的高效训练不仅需要紧凑数据子集，还需要保留感知的学习策略和明智的域排序，强调了数据为中心设计的重要性。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [35] [An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention](https://arxiv.org/abs/2511.04811)
*Shuo Zhao,Yu Zhou,Jianxu Chen*

Main category: cs.CV

TL;DR: 提出了一种结合基础模型和主动学习的数据中心AI工作流，用于生物医学图像分割，显著减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 传统方法处理噪声数据困难，nnU-Net需要大量标注数据，而基础模型在特定数据集上表现不佳。需要一种减少人工干预的解决方案。

Method: 使用基础模型生成伪标签用于nnU-Net自配置，然后通过主动学习选择代表性样本进行最小化人工标注，最后微调nnU-Net模型。

Result: 显著减少了手动标注需求，同时保持了有竞争力的分割性能。

Conclusion: 为生物医学研究人员提供了一种可访问的解决方案，能够在分割任务中应用最先进的AI技术。

Abstract: Biomedical image segmentation is critical for precise structure delineation
and downstream analysis. Traditional methods often struggle with noisy data,
while deep learning models such as U-Net have set new benchmarks in
segmentation performance. nnU-Net further automates model configuration, making
it adaptable across datasets without extensive tuning. However, it requires a
substantial amount of annotated data for cross-validation, posing a challenge
when only raw images but no labels are available. Large foundation models offer
zero-shot generalizability, but may underperform on specific datasets with
unique characteristics, limiting their direct use for analysis. This work
addresses these bottlenecks by proposing a data-centric AI workflow that
leverages active learning and pseudo-labeling to combine the strengths of
traditional neural networks and large foundation models while minimizing human
intervention. The pipeline starts by generating pseudo-labels from a foundation
model, which are then used for nnU-Net's self-configuration. Subsequently, a
representative core-set is selected for minimal manual annotation, enabling
effective fine-tuning of the nnU-Net model. This approach significantly reduces
the need for manual annotations while maintaining competitive performance,
providing an accessible solution for biomedical researchers to apply
state-of-the-art AI techniques in their segmentation tasks. The code is
available at https://github.com/MMV-Lab/AL_BioMed_img_seg.

</details>


### [36] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 提出了一种基于表面法向量先验知识的几何去噪新范式，通过标签向量集进行分割，结合总变差正则化，使用分裂Bregman方法求解优化问题。


<details>
  <summary>Details</summary>
Motivation: 利用表面法向量的先验知识来改进几何去噪效果，将分割问题自然地嵌入到去噪过程中。

Method: 使用标签向量集作为法向量先验，基于法向量相似性进行分割，采用总变差正则化，通过分裂Bregman（ADMM）方法求解优化问题，顶点更新基于二阶形状微积分。

Result: 该方法将几何去噪与分割相结合，通过先验法向量知识提升去噪质量。

Conclusion: 提出的新范式成功地将法向量先验知识整合到几何去噪中，实现了去噪与分割的统一处理。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [37] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 提出一种隐式自先验方法，直接从输入点云中学习形状特定的几何先验，结合隐式神经表示和鲁棒隐式移动最小二乘法，实现高质量表面重建。


<details>
  <summary>Details</summary>
Motivation: 从不规则点云恢复高质量表面是病态问题，需要强几何先验。传统方法依赖外部训练数据，本文旨在直接从输入点云本身学习形状特定的先验。

Method: 联合训练可学习嵌入字典与隐式距离场，通过交叉注意力机制捕获形状的重复结构和长程相关性。使用自监督点云重建损失优化，无需外部数据。结合RIMLS方法集成密集点云和法向量。

Result: 实验表明该方法在生成高保真表面方面优于经典和基于学习的方法，具有更好的细节保持和对常见数据退化的鲁棒性。

Conclusion: 提出的隐式自先验方法能够有效从点云中学习形状特定的几何先验，结合神经表示和传统优化方法，实现高质量表面重建。

Abstract: Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [38] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: 提出Clinical-ComBAT方法，用于解决DW-MRI数据多中心采集时的扫描仪特异性偏差问题，相比传统ComBAT方法更适合临床场景。


<details>
  <summary>Details</summary>
Motivation: DW-MRI在评估神经退行性疾病和白质微结构方面很有效，但多中心数据存在扫描仪特异性偏差。传统ComBAT方法依赖线性协变量关系、同质人群、固定站点数量等假设，限制了其临床应用。

Method: Clinical-ComBAT独立处理每个站点，采用非线性多项式数据模型，以规范站点为参考进行站点特异性协调，包含可适应小队列的方差先验、超参数调优和协调评估的拟合优度指标。

Result: 在模拟和真实数据上验证了方法的有效性，显示扩散指标对齐改善，规范建模的适用性增强。

Conclusion: Clinical-ComBAT克服了传统方法的限制，为临床环境提供了更灵活有效的多中心数据协调解决方案。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [39] [Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects](https://arxiv.org/abs/2511.04872)
*James Ndubuisi,Fernando Auat,Marta Vallejo*

Main category: cs.CV

TL;DR: 本研究评估了视觉变换器模型（特别是Swin变换器）在提高耳科疾病诊断准确性方面的效果，发现虽然初始结果优异，但存在数据泄露问题，修正后模型性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 由于耳鼻喉科专家有27%的误诊率，提高耳科疾病诊断准确性至关重要。

Method: 使用智利大学临床医院耳鼻喉科的真实耳镜视频数据集，基于拉普拉斯和香农熵阈值选择帧，比较Swin变换器与传统CNN模型。

Result: 初始Swin v1和v2准确率分别为100%和99.1%，但发现数据泄露问题后，修正准确率降至83%和82%。

Conclusion: 视觉变换器虽有潜力，但必须在先进模型架构和有效数据预处理之间找到平衡，这对开发可靠的耳科疾病诊断模型至关重要。

Abstract: This study evaluates the efficacy of vision transformer models, specifically
Swin transformers, in enhancing the diagnostic accuracy of ear diseases
compared to traditional convolutional neural networks. With a reported 27%
misdiagnosis rate among specialist otolaryngologists, improving diagnostic
accuracy is crucial. The research utilised a real-world dataset from the
Department of Otolaryngology at the Clinical Hospital of the Universidad de
Chile, comprising otoscopic videos of ear examinations depicting various middle
and external ear conditions. Frames were selected based on the Laplacian and
Shannon entropy thresholds, with blank frames removed. Initially, Swin v1 and
Swin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,
marginally outperforming the ResNet model (99.5%). These results surpassed
metrics reported in related studies. However, the evaluation uncovered a
critical data leakage issue in the preprocessing step, affecting both this
study and related research using the same raw dataset. After mitigating the
data leakage, model performance decreased significantly. Corrected accuracies
were 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This
finding highlights the importance of rigorous data handling in machine learning
studies, especially in medical applications. The findings indicate that while
vision transformers show promise, it is essential to find an optimal balance
between the benefits of advanced model architectures and those derived from
effective data preprocessing. This balance is key to developing a reliable
machine learning model for diagnosing ear diseases.

</details>


### [40] [Beta Distribution Learning for Reliable Roadway Crash Risk Assessment](https://arxiv.org/abs/2511.04886)
*Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang*

Main category: cs.CV

TL;DR: 提出一种基于卫星影像的地理空间深度学习框架，用于预测致命交通事故风险，通过估计完整的Beta概率分布提供不确定性感知预测，在召回率上比基线方法提升17-23%。


<details>
  <summary>Details</summary>
Motivation: 传统交通安全研究孤立分析风险因素，忽视空间复杂性；传统神经网络风险估计器缺乏不确定性量化，限制了在关键决策中的应用。

Method: 利用卫星影像作为综合空间输入，捕捉细微空间模式和嵌入式环境风险因素，估计致命事故风险的完整Beta概率分布而非单一确定性输出。

Result: 模型在召回率指标上比基线方法提升17-23%，提供更优的校准性能，能够仅从卫星影像提供可靠且可解释的风险评估。

Conclusion: 该方法为自动驾驶提供更安全的导航支持，为城市规划者和政策制定者提供高度可扩展的工具，以公平且经济高效的方式提升道路安全。

Abstract: Roadway traffic accidents represent a global health crisis, responsible for
over a million deaths annually and costing many countries up to 3% of their
GDP. Traditional traffic safety studies often examine risk factors in
isolation, overlooking the spatial complexity and contextual interactions
inherent in the built environment. Furthermore, conventional Neural
Network-based risk estimators typically generate point estimates without
conveying model uncertainty, limiting their utility in critical
decision-making. To address these shortcomings, we introduce a novel geospatial
deep learning framework that leverages satellite imagery as a comprehensive
spatial input. This approach enables the model to capture the nuanced spatial
patterns and embedded environmental risk factors that contribute to fatal crash
risks. Rather than producing a single deterministic output, our model estimates
a full Beta probability distribution over fatal crash risk, yielding accurate
and uncertainty-aware predictions--a critical feature for trustworthy AI in
safety-critical applications. Our model outperforms baselines by achieving a
17-23% improvement in recall, a key metric for flagging potential dangers,
while delivering superior calibration. By providing reliable and interpretable
risk assessments from satellite imagery alone, our method enables safer
autonomous navigation and offers a highly scalable tool for urban planners and
policymakers to enhance roadway safety equitably and cost-effectively.

</details>


### [41] [Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation](https://arxiv.org/abs/2511.04920)
*Hu Gao,Xiaoning Lei,Ying Zhang,Xichen Xu,Guannan Jiang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 提出IMDNet网络，通过解耦多种退化成分来指导路径选择，实现多退化图像恢复，在保持单退化任务竞争力的同时，在多退化恢复中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像往往同时存在多种退化（如雨、噪声、雾霾），而现有方法大多只针对单一退化类型，限制了实际应用效果。

Method: 设计退化成分解耦块(DIDBlock)分离退化成分统计特征，融合块(FBlock)整合多层级退化信息，任务适应块(TABlock)动态激活或融合功能分支，构建紧密集成的IMDNet架构。

Result: 实验验证表明，该方法在多退化图像恢复中表现优越，同时在单退化任务中保持强大竞争力。

Conclusion: IMDNet通过解耦多退化成分和自适应路径选择，有效解决了多退化图像恢复问题，具有实际应用价值。

Abstract: Image restoration (IR) aims to recover clean images from degraded
observations. Despite remarkable progress, most existing methods focus on a
single degradation type, whereas real-world images often suffer from multiple
coexisting degradations, such as rain, noise, and haze coexisting in a single
image, which limits their practical effectiveness. In this paper, we propose an
adaptive multi-degradation image restoration network that reconstructs images
by leveraging decoupled representations of degradation ingredients to guide
path selection. Specifically, we design a degradation ingredient decoupling
block (DIDBlock) in the encoder to separate degradation ingredients
statistically by integrating spatial and frequency domain information,
enhancing the recognition of multiple degradation types and making their
feature representations independent. In addition, we present fusion block
(FBlock) to integrate degradation information across all levels using learnable
matrices. In the decoder, we further introduce a task adaptation block
(TABlock) that dynamically activates or fuses functional branches based on the
multi-degradation representation, flexibly selecting optimal restoration paths
under diverse degradation conditions. The resulting tightly integrated
architecture, termed IMDNet, is extensively validated through experiments,
showing superior performance on multi-degradation restoration while maintaining
strong competitiveness on single-degradation tasks.

</details>


### [42] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 本文提出了一个包含8775次牙科检查的多模态数据集，涵盖50000张口腔内图像、8056张X光片和详细文本记录。通过微调Qwen-VL模型在口腔异常分类和诊断报告生成任务上取得显著提升，验证了数据集在AI牙科医疗中的有效性。


<details>
  <summary>Details</summary>
Motivation: AI在口腔医疗领域的发展依赖于能够捕捉临床实践复杂性的大规模多模态数据集，目前缺乏这样的公开资源。

Method: 收集了2018-2025年间4800名患者的8775次牙科检查数据，包括图像和文本记录。使用Qwen-VL 3B和7B模型进行微调，评估其在六种口腔异常分类和从多模态输入生成完整诊断报告的任务表现。

Result: 微调后的模型在口腔异常分类和诊断报告生成任务上相比基础模型和GPT-4o取得了显著提升，验证了数据集的有效性。

Conclusion: 该公开数据集为AI牙科医疗研究提供了重要资源，能够有效推动AI驱动的口腔医疗解决方案发展。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [43] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 提出一种基于高维潜在空间表示和多智能体对抗强化学习(MAARL)的深度学习框架，用于开发鲁棒且自适应的水印方法，以解决深度伪造检测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展导致深度伪造日益逼真，现有被动检测器依赖特定伪造伪影难以泛化，而主动水印方法在鲁棒性和敏感性之间难以平衡。

Method: 开发可学习的水印嵌入器在潜在空间操作，利用MAARL范式让水印智能体通过与对抗攻击智能体模拟的良性/恶意图像操作交互，寻求鲁棒性和脆弱性的最优平衡。

Result: 在CelebA和CelebA-HQ基准测试中，该方法始终优于最先进方法，在挑战性操作场景下分别实现超过4.5%和5.3%的改进。

Conclusion: 该框架通过高维潜在空间表示和MAARL范式，成功开发出鲁棒且自适应的水印方法，有效解决了深度伪造检测中的关键挑战。

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [44] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: CLM系统通过将高斯分布数据卸载到CPU内存，仅在需要时加载到GPU，使3D高斯溅射(3DGS)能够在单个消费级GPU上渲染大规模场景。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽然渲染速度快、质量高，但在处理大规模或复杂场景时内存需求过大，超出大多数GPU的内存容量。

Method: 利用3DGS内存访问模式的观察，采用流水线化的卸载策略，重叠GPU-CPU通信、GPU计算和CPU计算，并减少通信量。

Result: 能够在单个RTX4090上渲染需要1亿个高斯分布的大规模场景，并实现最先进的重建质量。

Conclusion: CLM系统成功解决了3DGS在大规模场景中的内存限制问题，使其能够在消费级硬件上高效运行。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [45] [Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement](https://arxiv.org/abs/2511.04963)
*Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang*

Main category: cs.CV

TL;DR: PDS提出了一种用于fMRI-dMRI跨模态合成的模式感知双模态3D扩散框架，通过组织精炼网络保持结构保真度，在神经退行性疾病诊断中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决fMRI和dMRI之间显著的BOLD信号与扩散加权信号差异，以及生成过程中疾病相关神经解剖模式整合不足的问题。

Method: 采用模式感知双模态3D扩散框架进行跨模态学习，结合组织精炼网络和高效微结构精炼来保持结构保真度和细节。

Result: 在OASIS-3、ADNI和内部数据集上达到最先进水平，fMRI合成PSNR/SSIM为29.83 dB/90.84%，dMRI合成PSNR/SSIM为30.00 dB/77.55%。临床验证中在NC vs. MCI vs. AD分类中达到67.92%/66.02%/64.15%准确率。

Conclusion: PDS方法在fMRI-dMRI跨模态合成方面表现出色，合成的数据在临床诊断中具有强大性能，为神经退行性疾病研究提供了有效工具。

Abstract: Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and
diffusion MRI (dMRI), is essential for studying neurodegenerative diseases.
However, missing modalities pose a major barrier to their clinical use.
Although GAN- and diffusion model-based approaches have shown some promise in
modality completion, they remain limited in fMRI-dMRI synthesis due to (1)
significant BOLD vs. diffusion-weighted signal differences between fMRI and
dMRI in time/gradient axis, and (2) inadequate integration of disease-related
neuroanatomical patterns during generation. To address these challenges, we
propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D
diffusion framework for cross-modality learning, and (2) a tissue refinement
network integrated with a efficient microstructure refinement to maintain
structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house
datasets, our method achieves state-of-the-art results, with PSNR/SSIM scores
of 29.83 dB/90.84\% for fMRI synthesis (+1.54 dB/+4.12\% over baselines) and
30.00 dB/77.55\% for dMRI synthesis (+1.02 dB/+2.2\%). In clinical validation,
the synthesized data show strong diagnostic performance, achieving
67.92\%/66.02\%/64.15\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic
experiments. Code is available in \href{https://github.com/SXR3015/PDS}{PDS
GitHub Repository}

</details>


### [46] [Learning Fourier shapes to probe the geometric world of deep neural networks](https://arxiv.org/abs/2511.04970)
*Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li*

Main category: cs.CV

TL;DR: 该论文提出了一个可微分框架，通过傅里叶级数参数化任意形状，探究深度神经网络对几何形状的理解能力，发现优化形状可作为语义载体、解释性工具和对抗攻击手段。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络研究主要关注纹理特征，而对几何理解能力缺乏系统探究，需要开发工具来分析和理解DNN的几何感知能力。

Method: 开发端到端可微分框架，结合傅里叶级数参数化形状、基于环绕数的像素网格映射，以及信号能量约束来确保物理合理性。

Result: 优化形状能产生高置信度分类，精确识别模型显著区域，并构成新的可泛化对抗攻击范式欺骗下游视觉任务。

Conclusion: 该工作为探究DNN的几何世界提供了多功能框架，为挑战和理解机器感知开辟了新前沿。

Abstract: While both shape and texture are fundamental to visual recognition, research
on deep neural networks (DNNs) has predominantly focused on the latter, leaving
their geometric understanding poorly probed. Here, we show: first, that
optimized shapes can act as potent semantic carriers, generating
high-confidence classifications from inputs defined purely by their geometry;
second, that they are high-fidelity interpretability tools that precisely
isolate a model's salient regions; and third, that they constitute a new,
generalizable adversarial paradigm capable of deceiving downstream visual
tasks. This is achieved through an end-to-end differentiable framework that
unifies a powerful Fourier series to parameterize arbitrary shapes, a winding
number-based mapping to translate them into the pixel grid required by DNNs,
and signal energy constraints that enhance optimization efficiency while
ensuring physically plausible shapes. Our work provides a versatile framework
for probing the geometric world of DNNs and opens new frontiers for challenging
and understanding machine perception.

</details>


### [47] [Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features](https://arxiv.org/abs/2511.04972)
*Dylan Peek,Matthew P. Skerritt,Siddharth Pritam,Stephan Chalup*

Main category: cs.CV

TL;DR: 本文提出了一种使用排斥表面算法生成带标签3D数据集的新方法，用于训练拓扑数据分析中的神经网络估计器，解决了该领域缺乏标注数据的问题。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑数据分析方法如持续同调计算成本高，而神经网络估计器需要专门设计的带标签3D数据集进行监督学习，但现有数据缺乏类别分布和多样性。

Method: 使用排斥表面算法系统生成带标签3D数据集，控制拓扑不变量（如孔洞数量），并采用3D卷积transformer架构训练属数估计网络。

Result: 生成的数据集具有几何多样性和拓扑标注，适合训练神经网络估计器。观察到随着形变增加，准确率下降，表明几何复杂性对泛化估计器训练的重要性。

Conclusion: 该数据集填补了拓扑数据分析中用于训练和评估模型的带标签3D数据集的空白，强调了拓扑和几何复杂性在训练泛化估计器中的共同作用。

Abstract: Topological Data Analysis (TDA) involves techniques of analyzing the
underlying structure and connectivity of data. However, traditional methods
like persistent homology can be computationally demanding, motivating the
development of neural network-based estimators capable of reducing
computational overhead and inference time. A key barrier to advancing these
methods is the lack of labeled 3D data with class distributions and diversity
tailored specifically for supervised learning in TDA tasks. To address this, we
introduce a novel approach for systematically generating labeled 3D datasets
using the Repulsive Surface algorithm, allowing control over topological
invariants, such as hole count. The resulting dataset offers varied geometry
with topological labeling, making it suitable for training and benchmarking
neural network estimators. This paper uses a synthetic 3D dataset to train a
genus estimator network, created using a 3D convolutional transformer
architecture. An observed decrease in accuracy as deformations increase
highlights the role of not just topological complexity, but also geometric
complexity, when training generalized estimators. This dataset fills a gap in
labeled 3D datasets and generation for training and evaluating models and
techniques for TDA.

</details>


### [48] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了贴纸语义相似度任务，创建了首个基准数据集Triple-S，并开发了轻量级通用贴纸编码器GSE，在贴纸理解和检索任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 贴纸已成为流行的视觉交流形式，但由于其内容高度多样化和符号化，理解贴纸间的语义关系仍然具有挑战性。

Method: 定义了贴纸语义相似度任务，构建了包含905个人工标注贴纸对的Triple-S基准数据集，提出了通用贴纸编码器GSE学习鲁棒的贴纸嵌入表示。

Result: GSE在未见过的贴纸上表现优异，在情感分类和贴纸检索等下游任务上取得强劲结果。现有预训练视觉和多模态模型难以捕捉贴纸的细微语义。

Conclusion: 通过发布Triple-S基准和GSE模型，为贴纸理解、检索和多模态内容生成研究提供了标准化评估工具和鲁棒嵌入表示。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [49] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 本文发现当前LVLM架构存在语言模态偏见，并提出通过视觉特征增强文本嵌入的简单有效方法，显著改善视觉定位并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 识别主流LVLM架构中存在的语言模态偏见问题，这种偏见主要源于将视觉嵌入简单附加到输入文本序列的常见做法。

Method: 提出一种简单有效的方法，通过整合平均池化的视觉特征来精炼文本嵌入，从而改善视觉定位能力。

Result: 该方法在已有基准测试中显著提高了视觉定位性能，并大幅减少了幻觉现象。

Conclusion: 平均池化提供了一种简单、鲁棒且高效的视觉信息整合方式，但更复杂的融合方法可能进一步提升视觉定位和跨模态对齐性能。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>
