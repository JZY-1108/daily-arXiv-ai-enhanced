<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 13]
- [cs.CV](#cs.CV) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本文提出了一种基于大五人格特质来控制LLM个性表达的新方法，通过提取隐藏状态激活、发现低秩子空间，并实现动态层选择和精确的个性控制。


<details>
  <summary>Details</summary>
Motivation: LLM在生成中表现出隐含个性，但可靠控制或对齐这些特质以满足特定需求仍是一个开放挑战。需要有效的机制来在生成过程中操纵模型行为。

Method: 提出新颖流程：从transformer层提取隐藏状态激活（基于大五人格特质），应用低秩子空间发现方法，识别跨不同模型架构的特质特定最优层进行稳健注入，并通过动态层选择的灵活引导框架操作化。

Result: 发现人格特质占据低秩共享子空间，这些潜在结构可通过精心扰动转化为有效的引导机制，而不影响流畅性、方差和通用能力。

Conclusion: 该方法有助于弥合心理学理论与实际模型对齐之间的差距，为个性感知LLM提供了有前景的方向。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [2] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个基于大语言模型的验证框架，通过思维链分解、变体生成、多数投票和共识聚合四阶段工作流，为TextGrad提供自我验证机制，显著提升推理有效性和优化性能。


<details>
  <summary>Details</summary>
Motivation: TextGrad作为文本自动微分方法缺乏自我验证机制，无法确保文本推理的有效性，这限制了其在复合AI系统中的可靠应用。

Method: 采用四阶段工作流：思维链分解、变体生成、多数投票和共识聚合，非侵入式集成到TextGrad的损失函数和优化结果验证阶段。

Result: 在PRM800K上推理步骤有效性提升29%；集成到TextGrad后在GPQA-Diamond、MMLU-ML、MMLU-CP基准上分别获得8.08、10.71、3.92个百分点的性能提升，损失函数集成使准确率从68.2%提升至70.4%。

Conclusion: TextualVerifier是首个基于LLM技术为TextGrad提供的自我验证框架，无需数值梯度即可实现更可靠的推理，为文本优化中的验证开辟了新方向。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [3] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: 扩展希腊方言数据集GRDD+，新增6种方言变体，总规模达637万词，包含10种希腊方言变体。对多个LLM进行微调实验，比较不同模型架构在方言处理上的表现。


<details>
  <summary>Details</summary>
Motivation: 构建首个具有如此规模和多样性的希腊方言数据集，研究高质量方言数据对大型语言模型性能的影响。

Method: 扩展GRDD数据集，新增Cretan、Cypriot等方言数据，并加入Greco-Corsican、Griko等6种新变体。对Llama-3-8B、Llama-3.1-8B、Krikri-8B三种模型进行微调，并与前沿模型Claude-3.7-Sonnet、Gemini-2.5、ChatGPT-5进行比较。

Result: 创建了包含10种希腊方言变体、总规模6,374,939词的数据集，这是迄今为止首个具有如此变异性和规模的数据集。

Conclusion: 该研究提供了希腊方言处理的重要资源，并通过微调实验展示了方言数据对LLM性能的积极影响，为方言语言模型研究奠定了基础。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [4] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是专为波兰语开发的最大开源基础模型家族，旨在解决英语主导的AI生态中其他语言支持不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要针对英语开发，对其他语言支持有限。PLLuM旨在为波兰语提供高质量、透明且文化相关的语言模型，超越以英语为中心的商业格局。

Method: 构建了1400亿token的波兰语预训练语料库、77k自定义指令数据集和100k偏好优化数据集，采用负责任AI框架，包含严格数据治理和混合模块进行输出校正与安全过滤。

Result: 开发了基础模型和指令调优变体，展示了在公共管理下游任务中的实用性。

Conclusion: 通过公开发布这些模型，PLLuM旨在促进开放研究，加强波兰的主权AI技术。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [5] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS是一种解码时算法，通过迭代采样、评分和拒绝/接受固定长度的token片段来引导模型生成，显著提高计算效率和对齐质量


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法如微调计算成本高且效果不佳，而推理时方法如Best-of-N采样需要不切实际的计算量才能达到最优对齐

Method: STARS算法：在解码时迭代采样固定长度的token片段，使用奖励模型对每个片段进行评分，然后基于评分决定接受或拒绝该片段，从而早期纠正生成路径

Result: 在6个LLM上的实验显示，STARS在胜率上比监督微调(SFT)高出14.9个百分点，比直接偏好优化(DPO)高出4.3个百分点，与强Best-of-N基线表现相当

Conclusion: 细粒度、奖励引导的采样是传统微调和全序列排序方法的通用、鲁棒且高效的替代方案，用于对齐大语言模型

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [6] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 提出一种基于二分决策序列的高效多标签文本分类方法，通过将分类任务重构为独立的是/否查询，结合前缀缓存机制，在不损失准确性的情况下显著提升短文本推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多标签分类任务中的效率问题，特别是针对短文本推理场景，通过任务分解和缓存优化来提升性能。

Method: 将多标签分类重构为序列化二分决策，每个目标维度独立查询；采用LLM-to-SLM蒸馏，使用DeepSeek-V3生成标注数据来微调小模型；结合前缀缓存机制优化推理效率。

Result: 微调后的模型在训练维度上显著优于零样本基线，在情感文本分析的24个维度上表现出色，实现了效率与准确性的平衡。

Conclusion: 将多标签分类分解为二分查询，结合蒸馏和缓存感知推理，为基于LLM的分类提供了一个可扩展且有效的框架，方法具有通用性可跨领域应用。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [7] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 研究分析了三种低资源语言（阿法尔奥罗莫语、阿姆哈拉语、提格里尼亚语）机器翻译数据集中的性别偏见问题，发现数据集存在严重的男性偏向和有害内容。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言被纳入NLP研究，大规模数据收集往往重数量轻质量，可能导致技术性能差和产生有害偏见内容。

Method: 调查三种低资源语言机器翻译数据集的质量，重点关注数据集中的性别表征。

Result: 发现训练数据中政治和宗教领域文本占主导，基准数据集集中于新闻、健康、体育领域；存在严重的男性偏向（人名、动词语法性别、刻板印象）；发现了针对女性的有害和毒性描述，且数据量最大的语言问题最突出。

Conclusion: 数量不能保证质量，希望研究能促进对低资源语言数据集的进一步调查，及早缓解有害内容。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [8] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: GRAD是一种解码时方法，通过构建稀疏标记转移图来缓解LLM幻觉问题，无需重新训练模型，在多个问答基准测试中显著提升准确性和事实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部知识源，但基于提示的接地方法脆弱且对领域敏感，符号知识集成需要高昂的检索和格式化成本。

Method: 通过单次前向传播在检索语料上累积下一个标记的对数概率来构建稀疏标记转移图，在解码时自适应融合图检索的对数概率和模型对数概率。

Result: 在三个模型和多个问答基准测试中，GRAD始终优于基线方法，内在准确率提高9.7%，幻觉率降低8.6%，正确性提高6.9%。

Conclusion: GRAD提供了一种轻量级、即插即用的替代方案，证明语料级标记转移的统计证据可以有效引导生成更真实和可验证的输出。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [9] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: 本文研究了迭代参考游戏中人类和视觉语言模型的性能差异，发现在缺乏相关上下文时模型表现远低于人类，但在有相关上下文时模型性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 测试智能体在多轮语言环境中进行上下文敏感语用推理的能力，通过迭代参考游戏评估人类和机器模型的差异。

Method: 使用迭代参考游戏试验，改变上下文的数量、顺序和相关性，比较人类和视觉语言模型的表现。

Result: 无相关上下文时模型表现高于随机但远差于人类；有相关上下文时模型性能随试验次数显著提升；抽象指称的少样本参考游戏对机器学习模型仍是挑战。

Conclusion: 上下文相关性对模型性能至关重要，虽然模型在有相关上下文时能显著改善，但在复杂语用推理任务上仍与人类存在差距。

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [10] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 开发了人类繁荣地理指数(HFGI)，通过分析26亿条地理定位的美国推文，使用微调的大语言模型对48个繁荣指标进行分类，提供月度/年度的县/州级繁荣相关话语数据。


<details>
  <summary>Details</summary>
Motivation: 量化人类繁荣这一多维概念对于理解超越经济指标的社会福祉至关重要，现有测量方法往往缺乏精细的空间和时间分辨率。

Method: 分析2013-2023年约26亿条地理定位的美国推文，使用微调的大语言模型对表达进行分类，涵盖48个与哈佛全球繁荣研究框架一致的指标，包括对移民态度和腐败认知。

Result: 数据集提供了月度/年度的县/州级繁荣相关话语指标，经验证能准确代表基础概念，并与既定指标显示预期相关性。

Conclusion: 该资源能够以前所未有的分辨率进行福祉、不平等和社会变革的多学科分析，提供了过去十年美国社交媒体话语中反映的人类繁荣动态的见解。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [11] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 提出了一种通过向量翻译在多智能体系统中实现跨模型语义直接交换的方法，替代传统的token传递方式，减少计算开销并提升信息传输效率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，LLM通过纯token传递消息会丢弃大部分潜在语义，限制了信息传输并增加了不必要的计算开销。

Method: 使用双编码器翻译器在Llama-2-7B和Mistral-7B-Instruct模型之间学习映射，实现表示空间的直接语义交换，并以30%的混合强度注入翻译后的向量。

Result: 获得了0.538的平均余弦对齐度，双向评估显示2.01:1的传输不对称性，表明通用模型比指令调优模型产生更可转移的表示。

Conclusion: 保守的向量注入保持了计算稳定性，证明了跨模型潜在通信的可行性，使协作AI系统能够共享意义而非token。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [12] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 提出一个将溯因推理整合到检索增强LLMs的框架，通过检测证据不足、生成候选缺失前提并进行验证，提高RAG系统的推理准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统RAG管道在检索证据不完整时会失败，留下推理空白。溯因推理能提供原则性方法来填补这些空白。

Method: 检测证据不足、生成候选缺失前提、通过一致性和合理性检查进行验证

Result: 在溯因推理和多跳QA基准测试中显示，该方法提高了答案准确性和推理可信度

Conclusion: 溯因推理是增强RAG系统鲁棒性和可解释性的有前景方向

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [13] [WST: Weakly Supervised Transducer for Automatic Speech Recognition](https://arxiv.org/abs/2511.04035)
*Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu*

Main category: cs.CL

TL;DR: 提出弱监督转换器（WST）来解决RNN-T对高质量标注数据依赖的问题，能够在转录错误率高达70%的情况下保持性能，优于现有的CTC基弱监督方法。


<details>
  <summary>Details</summary>
Motivation: RNN-T在端到端语音识别中广泛应用，但严重依赖大规模高质量标注数据，这些数据成本高昂且难以获取。

Method: 提出弱监督转换器（WST），集成灵活的训练图设计，能够鲁棒地处理转录错误，无需额外的置信度估计或预训练模型。

Result: 在合成和工业数据集上的实证评估显示，WST在转录错误率高达70%时仍能有效保持性能，一致优于BTC和OTC等现有CTC基弱监督方法。

Conclusion: WST在实际ASR场景中具有实用性和鲁棒性，实现将公开可用。

Abstract: The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in
end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily
on large-scale, high-quality annotated data, which are often costly and
difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised
Transducer (WST), which integrates a flexible training graph designed to
robustly handle errors in the transcripts without requiring additional
confidence estimation or auxiliary pre-trained models. Empirical evaluations on
synthetic and industrial datasets reveal that WST effectively maintains
performance even with transcription error rates of up to 70%, consistently
outperforming existing Connectionist Temporal Classification (CTC)-based weakly
supervised approaches, such as Bypass Temporal Classification (BTC) and
Omni-Temporal Classification (OTC). These results demonstrate the practical
utility and robustness of WST in realistic ASR settings. The implementation
will be publicly available.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [14] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge是一种参数高效微调方法，结合低秩适应和Tensor-Train分解，用于边缘设备上CNN的轻量级微调，大幅减少可训练参数数量。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上进行CNN微调以应对领域偏移很重要，但受限于严格的内存、计算和能耗预算，完全微调不可行。

Method: 对预训练卷积层应用Tensor-Train SVD分解，仅选择性更新输出侧核心，使用零初始化保持辅助路径初始不活跃，最后将更新融合回密集核中。

Result: 在多种HAR数据集和CNN骨干网络上，LoRA-Edge仅更新最多1.49%的参数，就能达到与完全微调相差4.7%以内的准确率，收敛速度提升1.4-3.8倍。

Conclusion: LoRA-Edge实现了结构对齐、参数高效的边缘设备CNN自适应，为边缘平台提供了实用的解决方案。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [15] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一个开源视频标注软件，专门用于标注动物行为中的交互作用，填补了现有工具在行为标注和个体定位功能之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有开源标注工具要么只支持行为标注而不定位个体，要么只定位个体而不能捕捉交互作用，这限制了计算机视觉方法在动物社交行为分析中的应用。

Method: 开发了SILVI软件，集成行为标注和个体定位功能，允许研究者在视频数据中直接标注行为和交互，生成适合训练计算机视觉模型的结构化输出。

Result: SILVI成功连接了行为生态学和计算机视觉，为细粒度行为分析自动化方法的发展提供了支持。

Conclusion: SILVI填补了动物行为分析中交互标注工具的空白，虽然主要针对动物行为开发，但也可广泛应用于需要提取动态场景图的人类交互标注。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [16] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 该论文研究通过噪声注入技术提高COVID-19胸部X光检测模型的分布外泛化能力，将ID与OOD性能差距从0.10-0.20降低到0.01-0.06。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像识别中容易学习源特定伪影而非真实生物标志物，导致在分布外数据上泛化失败，特别是在COVID-19胸部X光检测中。

Method: 在训练过程中使用基础噪声注入技术（高斯、散斑、泊松和椒盐噪声）来提高模型对分布偏移的鲁棒性。

Result: 实验结果显示，该方法显著缩小了ID与OOD评估之间的性能差距，从0.10-0.20降低到0.01-0.06，基于AUC、F1、准确率、召回率和特异性等关键指标。

Conclusion: 噪声注入是一种有效的技术，可以提高COVID-19检测模型在分布外数据上的泛化能力，减少对源特定伪影的依赖。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [17] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 该研究探索了在双平面X射线引导下脊柱手术中应用模仿学习策略的可行性，开发了高真实度仿真环境并训练了基于视觉信息的插管对齐策略。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在视频机器人控制中重新受到关注，但尚不清楚是否适用于X射线引导的脊柱手术，因为多视图X射线解释复杂。

Method: 开发了高真实度仿真环境，收集正确轨迹和对应双平面X射线序列数据集，训练基于视觉信息的模仿学习策略进行规划和开环控制。

Result: 策略在68.5%的情况下首次尝试成功，保持了安全的椎弓根内轨迹，能泛化到复杂解剖结构（包括骨折），并在真实X射线上产生合理轨迹。

Conclusion: 初步结果有前景，但存在入口点精度限制，完全闭环控制需要更频繁的反馈机制，结合更强先验和领域知识可为无CT的机器人脊柱导航奠定基础。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [18] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 提出基于轻量化YOLOv12结合自对抗训练和专用数据增强的实时目标检测框架，用于沙漠环境中的废物检测，在精度和效率方面取得显著改进


<details>
  <summary>Details</summary>
Motivation: 全球废物危机加剧，传统废物收集方法在偏远环境效率低下且危险，现有研究主要关注城市环境和可回收材料，忽视了有机危险废物和沙漠等未充分探索的地形

Method: 使用修剪轻量化的YOLOv12模型，集成自对抗训练(SAT)和专用数据增强策略，在DroneTrashNet数据集上进行训练

Result: 在精度、召回率和mAP方面显著提升，同时实现低延迟和紧凑模型尺寸，适合在资源受限的无人机上部署，在准确性和效率之间达到最佳平衡

Conclusion: 验证了数据中心和模型中心增强相结合对于沙漠环境中稳健实时废物检测的有效性

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [19] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 提出Class-Based Image Composition方法，通过将同类多张图像融合成组合视觉图像(CoImg)来增强训练数据，有效解决小样本、不平衡数据集和图像质量差导致的深度学习模型误判问题。


<details>
  <summary>Details</summary>
Motivation: 解决小样本、不平衡数据集和输入图像质量差导致深度学习模型误判率高的问题，增强模型对细微疾病模式的区分能力。

Method: 采用类基图像组合方法，将同类多张图像融合成组合视觉图像(CoImg)，构建平衡数据集Co-OCTDL，使用VGG16模型进行对比分析。

Result: 在OCTDL数据集上，改进方法达到近乎完美的准确率(99.6%)、F1分数(0.995)和AUC(0.9996)，误判率显著降低。

Conclusion: 该方法即使对于受类别不平衡或小样本影响的弱数据集，也能产生高质量预测结果，显著提升诊断性能。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [20] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 提出了一种无监督、无需专家标注的医学图像异常检测框架，通过增量扩展正常样本集，结合轻量级适配器更新和不确定性门控样本准入机制，在多个医学影像数据集上显著提升了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的未知异常检测面临标注异常样本稀缺和专家监督成本高昂的挑战，需要开发无需异常标签的自动检测方法。

Method: 使用预训练视觉主干网络配合微小卷积适配器进行快速领域适应，通过k近邻异常评分和双重概率门控机制（距离z-score阈值和SWAG认知不确定性）安全扩展正常样本集。

Result: 在COVID-CXR数据集上ROC-AUC从0.9489提升到0.9982，F1从0.8048提升到0.9746；在Pneumonia CXR上ROC-AUC从0.6834提升到0.8968；在Brain MRI ND-5上ROC-AUC从0.6041提升到0.7269，PR-AUC从0.7539提升到0.8211。

Conclusion: 该框架在标签稀缺的真实世界医学影像应用中表现出高效性和有效性，能够稳定地精炼正常性概念，显著优于基线方法。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [21] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 本文提出了边界距离回归(BDR)和自适应时序精化(ATR)两个互补方法，通过优化边界检测的计算分配，显著提升时序动作定位性能。


<details>
  <summary>Details</summary>
Motivation: 当前时序动作定位方法对所有边界采用统一计算，忽视了不同边界难度的显著差异，导致计算效率低下。

Method: BDR使用带符号距离回归替代分类，实现信息理论最优定位；ATR通过连续深度选择τ∈[0,1]分配计算，支持端到端可微优化。

Result: 在THUMOS14上，ATR在162G FLOPs下达到56.5% mAP@0.7，相比均匀处理的53.6%(198G FLOPs)，性能提升2.9%且计算减少18%。BDR可轻松集成到现有方法中，带来1.8-3.1%的mAP@0.7提升。

Conclusion: 该方法通过自适应计算分配有效解决了边界检测中的计算效率问题，在多个基准测试中验证了显著性能提升，特别对短动作效果更佳。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [22] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 提出一种统一处理几何和外观优化的高斯-网格联合优化框架，通过高斯引导的网格可微分渲染同时优化网格几何和顶点颜色，实现高质量3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常在几何精度和真实感渲染之间权衡，将几何和外观优化解耦，这阻碍了下游编辑任务。需要统一的几何和外观优化方法。

Method: 同时优化网格几何（顶点位置和面）和顶点颜色，利用高斯引导的网格可微分渲染，结合输入图像的光度一致性和法向/深度图的几何正则化。

Result: 获得了高质量的3D重建结果，可用于下游编辑任务如重光照和形状变形。

Conclusion: 提出的高斯-网格联合优化框架实现了几何和外观的统一优化，为3D编辑应用提供了高质量的3D重建基础。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [23] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 提出了一种基于线性分式变换参数α的方法，用于解耦光场相机的主镜头和微透镜阵列，实现精确的内参标定。该方法包含基于最小二乘的解析解和非线性优化，并提出了从原始图像中检测特征的方法。


<details>
  <summary>Details</summary>
Motivation: 光场相机内部参数的精确标定是3D重建的关键但具有挑战性的前提条件。需要解决主镜头和微透镜阵列之间的耦合问题。

Method: 使用线性分式变换参数α解耦主镜头和微透镜阵列，包括基于最小二乘的解析解和非线性优化，并提出了从原始图像中检测特征的方法。

Result: 在物理和模拟数据上的实验结果验证了所提方法的性能。基于该模型，原始光场图像的模拟速度更快，这对数据驱动的深度学习方法至关重要。

Conclusion: 提出的方法能够有效解决光场相机内参标定问题，提高了标定精度和效率，为基于深度学习的应用提供了更好的数据支持。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>
